<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Le Bail Fit - Help</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    
    <script>
        MathJax = {
          tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']]
          },
          svg: {
            fontCache: 'global'
          }
        };
    </script>
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
    </script>

    <style>
        :root {
            --system-blue: #007AFF;
            --system-gray-1: #8E8E93;
            --system-gray-2: #AEAEB2;
            --system-gray-3: #C7C7CC;
            --system-gray-4: #D1D1D6;
            --system-gray-5: #E5E5EA;
            --system-gray-6: #F2F2F7;
            --system-background: #FFFFFF;
            --system-grouped-background: #F2F2F7;
            --system-label: #000000;
            --system-secondary-label: rgba(60, 60, 67, 0.6);
            --system-separator: rgba(60, 60, 67, 0.29);
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Inter', sans-serif;
            margin: 0;
            background-color: var(--system-grouped-background);
            display: flex;
            flex-direction: column;
            height: 100vh;
            color: var(--system-label);
            line-height: 1.7;
            font-size: 16px;
        }

        #app-container {
            display: flex;
            width: 100%;
            height: 100%;
            overflow: hidden;
        }

        #nav-panel {
            width: 280px;
            min-width: 240px;
            flex-shrink: 0;
            padding: 24px;
            background-color: var(--system-background);
            border-right: 1px solid var(--system-separator);
            overflow-y: auto;
        }

        #nav-panel h2 {
            font-size: 18px;
            margin-top: 0;
            margin-bottom: 24px;
            color: var(--system-label);
        }

        #nav-panel ul {
            list-style: none;
            padding: 0;
            margin: 0;
        }

        #nav-panel li a {
            display: block;
            padding: 8px 12px;
            text-decoration: none;
            color: var(--system-secondary-label);
            border-radius: 8px;
            font-weight: 500;
            transition: all 0.2s ease;
            font-size: 15px;
        }
        
        #nav-panel li a.sub-link {
            padding-left: 28px;
            font-size: 14px;
            font-weight: 400;
        }

        #nav-panel li a:hover {
            background-color: var(--system-gray-6);
            color: var(--system-label);
        }

        #nav-panel li a.active {
            background-color: var(--system-blue);
            color: white;
            font-weight: 600;
        }


        #content-area {
            flex-grow: 1;
            padding: 32px 48px;
            overflow-y: auto;
            background-color: var(--system-background);
        }
        
        #content-area h2 {
            font-size: 28px;
            font-weight: 700;
            margin-top: 0;
            padding-bottom: 16px;
            border-bottom: 1px solid var(--system-separator);
            margin-bottom: 24px;
        }
        
        #content-area h3 {
            font-size: 22px;
            font-weight: 600;
            margin-top: 40px;
            margin-bottom: 16px;
            padding-bottom: 8px;
            border-bottom: 1px solid var(--system-gray-5);
        }
        
        #content-area h4 {
            font-size: 18px;
            font-weight: 600;
            margin-top: 24px;
            margin-bottom: 12px;
            color: var(--system-secondary-label);
        }

        code {
            background-color: var(--system-gray-6);
            padding: 2px 6px;
            border-radius: 4px;
            font-family: 'SF Mono', 'Menlo', 'monospace';
            font-size: 0.9em;
            border: 1px solid var(--system-gray-4);
        }
        
        .reference-item {
            margin-bottom: 1em;
        }

        .note {
            background-color: #eef6ff;
            border-left: 4px solid var(--system-blue);
            padding: 16px;
            margin: 24px 0;
            border-radius: 0 8px 8px 0;
        }
    </style>
</head>
<body>

<div id="app-container">
    <nav id="nav-panel">
        <h2>Help Topics</h2>
        <ul id="nav-links">
            <li><a href="#introduction">Introduction</a></li>
            <li><a href="#getting-started">Getting Started</a></li>
            <li><a href="#chart-interactions">Chart Interactions</a></li>
            <li><a href="#decomposition-methods">Decomposition Methods</a></li>
            <li><a href="#le-bail-method" class="sub-link">Le Bail Method</a></li>
            <li><a href="#pawley-method" class="sub-link">Pawley Method</a></li>
            <li><a href="#algorithms">Refinement Algorithms</a></li>
            <li><a href="#algorithms-lm" class="sub-link">Levenberg-Marquardt</a></li>
            <li><a href="#algorithms-sa" class="sub-link">Simulated Annealing</a></li>
            <li><a href="#parameters">Parameter Guide</a></li>
            <li><a href="#parameters-crystal" class="sub-link">Crystal & Space Group</a></li>
            <li><a href="#parameters-instrumental" class="sub-link">Instrumental</a></li>
            <li><a href="#parameters-background" class="sub-link">Background</a></li>
            <li><a href="#parameters-profile4" class="sub-link">Profile Function #4</a></li>
            <li><a href="#parameters-profile3" class="sub-link">Profile Function #3</a></li>
            <li><a href="#strategy">Refinement Strategy</a></li>
            <li><a href="#results">Interpreting Results</a></li>
            <li><a href="#references">References</a></li>
            <li><a href="#about">About</a></li>
        </ul>
    </nav>

    <main id="content-area">
        <section id="introduction">
            <h2>Introduction</h2>
            <p>
                Welcome to the guide for the <strong>powder5</strong> toolkit, a modern web application for analyzing powder X-ray diffraction (PXRD) data. This tool is designed for material scientists, chemists, and crystallographers who need to perform "whole-pattern fitting" or "pattern decomposition." This technique is useful when you know the crystal symmetry (space group and lattice parameters) but don't know the exact atomic positions, or when you simply need to extract precise information about the crystal lattice and peak shapes from your data.
            </p>
            <p>
                The application implements two renowned decomposition algorithms: the fast and stable iterative <strong>Le Bail method</strong> and the comprehensive simultaneous <strong>Pawley method</strong>. To accurately model the shape of the diffraction peaks, it uses profile functions adapted from GSAS software package. You can choose between a <strong>Simple pseudo-Voigt (Profile Function #4)</strong> and a <strong>Anisotropy model (Profile Function #3)</strong>, which accounts for direction-dependent peak broadening.
            </p>
        </section>
        
        <hr>
        
        <section id="getting-started">
            <h2>Getting Started: Loading Your Data</h2>
            <p>
                The analysis begins by loading a powder diffraction data file using the "Select Data File" button. The application is built to recognize and automatically parse many common file formats from different instrument manufacturers.
            </p>
            <ul>
                <li><b>Supported Formats:</b> The tool has built-in parsers for Bruker (<code>.brml</code>, <code>.uxd</code>), PANalytical (<code>.xrdml</code>), Rigaku (<code>.ras</code>), Philips (<code>.udf</code>), and GSAS (<code>.esd</code>, <code>.gsa</code>, <code>.xra</code>).</li>
                <li><b>Generic Data:</b> If you have a simple two-column text file (e.g., from a spreadsheet or another program), the tool can likely read it. It supports columns separated by spaces, commas, or semicolons, with the first column being $2\theta$ and the second being intensity. Lines starting with <code>#</code> are treated as comments and ignored.</li>
                <li><b>Automatic Wavelength Detection:</b> For many instrument-specific files, the tool will read the X-ray wavelength (usually Cu Kα1) from the file's metadata and pre-fill the "Radiation 1 (Å)" field for you. However, it's always good practice to double-check that this value is correct for your experiment.</li>
            </ul>
        </section>

        <hr>

        <section id="chart-interactions">
            <h2>Navigating the Diffraction Pattern</h2>
            <p>The diffraction pattern plot is fully interactive, giving you the power to inspect your data and the quality of your fit in detail.</p>
            <ul>
                <li><b>Pan:</b> To move around the pattern, simply click and drag anywhere on the chart. This lets you explore the entire dataset, even regions outside the range you've selected for refinement.</li>
                <li><b>Zoom:</b> Use your mouse wheel to zoom in and out. The zoom is anchored to your cursor's position and behaves differently depending on where you are:
                    <ul>
                        <li><b>Over the plot area:</b> Zooms both axes together.</li>
                        <li><b>Over the Intensity (Y) axis on the left:</b> Zooms only vertically.</li>
                        <li><b>Over the $2\theta$ (X) axis at the bottom:</b> Zooms only horizontally.</li>
                    </ul>
                </li>
                <li><b>Reset View:</b> If you get lost in your zoom, just <strong>right-click</strong> anywhere on the chart. This instantly resets the view to the range currently defined by the <strong>2θ Min/Max sliders</strong>.</li>
                <li><b>Peak Information:</b> Hover your cursor near one of the green tick marks at the bottom of the plot. A tooltip will appear, showing you the Miller indices ($hkl$) for that Bragg reflection.</li>
                <li><b>Add Background Anchors:</b> To help guide the background fit, hold down the <strong>Ctrl</strong> key and <strong>click</strong> on a point in the pattern. The nearest experimental data point will be marked as an "anchor," forcing the background curve to pass close to it during refinement.</li>
            </ul>
        </section>
        
        <hr>
        
        <section id="decomposition-methods">
            <h2>Choosing Your Decomposition Method</h2>
            <p>
               Pattern decomposition is a powerful technique that allows you to fit an entire diffraction pattern to a unit cell without knowing the specific arrangement of atoms inside it. This is invaluable for accurately determining lattice parameters and for extracting the integrated intensities of each peak, which can then be used for solving the full crystal structure. This tool offers the two most common methods.
            </p>
            <h3 id="le-bail-method">The Le Bail Method: The Fast & Stable Workhorse</h3>
            <p>
                The Le Bail method is a sequential process that is known for its speed and stability. It works in a repeating cycle:
            </p>
            <ol>
                <li><b>Guess & Calculate:</b> The algorithm starts with your initial guess for the lattice and profile parameters and assumes all peaks have the same intensity. It calculates a theoretical pattern based on this.</li>
                <li><b>Extract Intensities:</b> The algorithm compares the calculated pattern to your experimental data. It distributes the observed intensity at each point among the theoretical peaks that overlap at that position. By summing up these distributed portions for each peak, it generates a new set of "observed" integrated intensities ($I_{hkl}$).</li>
                <li><b>Refine & Repeat:</b> The algorithm now treats these newly extracted intensities as <strong>fixed constants</strong>. It performs a least-squares refinement to adjust the <strong>lattice, background, and profile parameters</strong> to better match the data. These new parameters are then used to start the cycle over again from Step 1.</li>
            </ol>
            <p>It is a negotiation in turns: first, you figure out the intensities, then you fix them and figure out the cell parameters and peak shape. You repeat this until nothing changes anymore.</p>

            <h3 id="pawley-method">The Pawley Method: The Comprehensive Simultaneous Fit</h3>
            <p>
                The Pawley method takes a different, more direct approach. Instead of iterating, it treats the integrated intensity ($I_{hkl}$) of every single Bragg peak as an <strong>independent, refinable variable</strong>.
            </p>
            <p>
                This means the algorithm attempts to solve for everything at once in a single, large least-squares refinement: all the lattice parameters, all the profile parameters, and all the individual peak intensities simultaneously.
            </p>
            <ul>
                <li><b>Strengths:</b> The Pawley method is theoretically more rigorous and can provide more accurate, unbiased integrated intensities. This is especially true when many peaks overlap, as it's less likely to make a strong peak "steal" intensity from a weak neighbor.</li>
                <li><b>Weaknesses:</b> Because it adds a new variable for every peak, the calculation is much more intensive. It can also be less stable and more prone to failure if your initial model is not very good.</li>
            </ul>
        </section>

        <hr>
        
        <section id="algorithms">
            <h2>Behind the Scenes: The Refinement Algorithms</h2>
            <p>To find the best-fit parameters, the program needs a mathematical strategy to minimize the difference between your data and the calculated pattern. This difference is quantified by the objective function, $\sum w_i (y_{i,obs} - y_{i,calc})^2$. This tool offers two distinct algorithms to perform this minimization.</p>

            <h3 id="algorithms-lm">Levenberg-Marquardt (LM): The Efficient Local Search</h3>
            <p>
                The LM algorithm is the industry standard for non-linear least-squares problems like this. It is a "local" minimizer, meaning it's very good at finding the bottom of the valley it's currently in. It works by analyzing the slope (gradient) of the objective function to determine the most direct path "downhill" toward a better fit.
            </p>
            <ul>
                <li>
                    <b>Analogy:</b> Imagine a hiker trying to get to the bottom of a valley in thick fog. They can't see the whole landscape, but they can feel the slope of the ground beneath their feet. LM is like an expert hiker who uses this information to take confident, rapid steps in the steepest downhill direction to reach the bottom of that valley quickly.
                </li>
                <li><b>Best For:</b> Rapidly converging to the precise best-fit solution when your starting parameters are already reasonably good. It also provides statistically meaningful error estimates (ESDs) on the refined parameters.</li>
                <li><b>Weakness:</b> If the hiker starts in the wrong valley, LM will efficiently find the bottom of that valley, completely unaware that a much deeper valley (the true global minimum) exists elsewhere.</li>
            </ul>
            
            <h3 id="algorithms-sa">Simulated Annealing (SA): The Adventurous Global Explorer</h3>
            <p>
                Simulated Annealing is a "global" optimization method inspired by the process of slowly cooling molten metal to form strong, defect-free crystals. The algorithm starts with a high "temperature" ($T$), which allows it to randomly explore the parameter landscape.
            </p>
            <p>
                 Initially, it is very "adventurous" and will frequently accept moves that temporarily make the fit worse. This crucial ability allows it to "jump" over hills and escape from shallow valleys (local minima). As the refinement progresses, the temperature is slowly lowered, making the algorithm more cautious. It becomes less likely to accept bad moves and eventually "freezes" into the lowest valley it has found.
            </p>
            <ul>
                <li><b>Best For:</b> Situations where you are unsure of your starting parameters, or when the LM algorithm seems to be stuck in a poor solution. It is excellent for finding a good starting point for a final, quick refinement using LM.</li>
                <li><b>Weakness:</b> It is much slower than LM and may not find the bottom of the final valley with the same high precision. It does not provide parameter uncertainties (ESDs).</li>
            </ul>
        </section>
        
        <hr>
        
        <section id="parameters">
            <h2>Guide to Refinable Parameters</h2>
            <p>This section provides a detailed breakdown of the parameters you can control and refine.</p>

            <h3 id="parameters-crystal">Crystal System & Space Group</h3>
            <p>
                These are the most fundamental parameters defining your material's crystal structure.
            </p>
            <ul>
                <li>The <strong>System</strong> dropdown sets the crystal system (e.g., Cubic, Orthorhombic). This automatically applies the necessary constraints on the lattice parameters, determining which ones are independent and need to be defined.</li>
                <li>The <strong>Space Group</strong> dropdown is then filtered based on the chosen system. Selecting the correct space group is essential, as it dictates the systematic absences (reflection conditions) and ensures that only the allowed Bragg peaks ($hkl$) are generated.</li>
            </ul>

            <h3 id="parameters-instrumental">Instrumental Parameters</h3>
            <p>
                Found under the "Sample" tab, these parameters model the experimental setup.
            </p>
            <ul>
                <li><code>Radiation 1/2 (Å) & Ratio</code>: These define your X-ray source. For most lab diffractometers, you'll use two wavelengths (Kα1 and Kα2) with a ratio of ~0.5. To model a single wavelength (e.g., from a synchrotron), set the Ratio to 0.</li>
                <li><code>Zero</code>: This refines the instrumental zero-point error, a small constant offset in the measured $2\theta$ values. It is highly correlated with lattice parameters and should be refined with care.</li>
                <li><code>2θ Min / Max</code>: These sliders are crucial. They define the portion of your dataset that will be used in the refinement calculation. It's often wise to exclude noisy regions at the very beginning or end of the pattern. Note that the Chebyshev background parameters are normalized to this specific range, so changing it will require re-fitting the background.</li>
            </ul>

            <h3 id="parameters-background">Background Modeling</h3>
            <p>The background signal is modeled using a combination of functions on the "Background" tab.</p>
             <ul>
                <li><b>Chebyshev Polynomial:</b> This is a flexible 6-term polynomial used to fit the broad, slowly varying background. Start by refining just the first few terms ($B_0$, $B_1$) and add higher-order terms only if necessary to model complex curvature.</li>
                <li><b>Amorphous Hump:</b> This adds a broad Lorentzian peak to the background, perfect for modeling scattering from an amorphous sample holder (like glass) or an amorphous component in your sample.</li>
                <li><b>Anchor Points:</b> This is a powerful manual tool. By <strong>Ctrl+Clicking</strong> on the chart in a region that is clearly background, you add an anchor point. During refinement, the algorithm is heavily penalized for deviating from this point, effectively forcing the background curve to pass through it. This is useful for complex backgrounds that the polynomial cannot easily model on its own.</li>
            </ul>


            <h3 id="parameters-profile4">Profile Function #4 (Simple pseudo-Voigt)</h3>
            <p>
                This profile function models the peak shape as a linear combination of a Gaussian and a Lorentzian function, controlled by a mixing parameter, $\eta$. It is a versatile and stable choice for many standard materials. The broadening of each component depends on the diffraction angle:
                $$H_G^2 = GU \tan^2\theta + GV \tan\theta + GW + GP / \cos^2\theta$$
                $$H_L = LX / \cos\theta$$
            </p>
            <ul>
                <li><code>GU, GV, GW, GP</code>: These parameters describe the angular dependence of the Gaussian broadening, which is related to instrumental effects and microstrain.</li>
                <li><code>LX</code>: This parameter describes the Lorentzian broadening, which is primarily related to the crystallite size.</li>
                <li><code>eta</code>: A simple mixing parameter, where $\eta=0$ is a pure Gaussian peak and $\eta=1$ is a pure Lorentzian peak.</li>
                <li><code>shft & trns</code>: These parameters correct for shifts in the peak position caused by sample displacement from the focusing circle and sample transparency to X-rays, respectively.</li>
            </ul>
            
            <h3 id="parameters-profile3">Profile Function #3 (Anisotropic TCH)</h3>
            <p>
                This is a more physically rigorous and powerful profile function adapted from GSAS. It combines the well-known <strong>Thompson-Cox-Hastings (TCH) pseudo-Voigt</strong> for the base peak shape with a model by <strong>Stephens</strong> to account for anisotropic (direction-dependent) broadening.
            </p>
            <div class="note">
                <b>Tip:</b> You can use this function as a standard isotropic TCH model (like GSAS Profile Function #2) by simply keeping all the Stephens <code>S_hkl</code> parameters fixed at zero.
            </div>
            
            <h4>Isotropic Broadening (TCH Model)</h4>
            <p>In the TCH formulation, the angular dependence of the Gaussian ($H_G$) and Lorentzian ($H_L$) components are modeled based on physical principles:
                $$H_G^2 = U \tan^2\theta + V \tan\theta + W$$
                $$H_L = X \tan\theta + Y / \cos\theta$$
            </p>
            <ul>
                <li><code>U, V, W</code>: These terms model the Gaussian broadening. $W$ is related to instrumental resolution (Caglioti formula), while $U$ and $V$ are related to microstrain and other instrumental factors.</li>
                <li><code>X, Y</code>: These terms model the Lorentzian broadening. $Y$ is primarily related to crystallite size (Scherrer formula), and $X$ is related to strain.</li>
            </ul>
            
            <h4>Peak Asymmetry</h4>
             <p>The <code>S/L</code> and <code>H/L</code> parameters introduce an angle-dependent asymmetry to the peak shape, which is often necessary to correctly model peaks at low angles that are distorted by instrumental effects like axial divergence.</p>

            <h4>Anisotropic Broadening (Stephens Model)</h4>
            <p>
                In some materials, the peaks are broader in certain crystallographic directions than in others. This anisotropic strain is modeled by adding extra terms to the Lorentzian broadening that depend on the Miller indices ($hkl$).
            </p>
            <p>
                The refinable parameters (<code>S400</code>, <code>S040</code>, etc.) are coefficients in this model. The tool automatically applies the correct symmetry constraints based on your selected crystal system. For example, in a <strong>cubic</strong> system, crystal symmetry dictates that $S400 = S040 = S004$, so only one of these parameters needs to be refined.
            </p>
        </section>

        <hr>
        
        <section id="strategy">
            <h2>A Practical Refinement Strategy</h2>
            <p>
                Jumping into a refinement by enabling all parameters at once is a common mistake that often leads to unstable results. A disciplined, sequential strategy is far more effective. The general philosophy is to establish a good fit for the major effects first (background and peak positions) before moving on to the more subtle details of peak shape.
            </p>
            
            <h3>Phase 1: Getting the Basics Right</h3>
            <ol>
                <li><b>Set the Stage:</b> Load your data and choose your crystal system and space group. Crucially, use the <strong>$2\theta$ sliders</strong> to define the range you want to fit. It's good practice to exclude noisy regions or areas with known impurity peaks.</li>
                <li><b>Model the Background:</b> Switch to the "Background" tab. Start by refining only the first two Chebyshev terms (<code>B0</code>, <code>B1</code>) to fit the general slope and height. If the background is complex, use <strong>Ctrl+Click</strong> to add anchor points in regions with no peaks to guide the fit.</li>
                <li><b>Find the Peak Positions:</b> Using the <strong>Le Bail</strong> method and the <strong>LM</strong> algorithm, refine only the <strong>Lattice Parameter(s)</strong> and the instrumental <strong>Zero Shift</strong>. Keep the profile shape fixed for now. Your goal here is simply to make the green tick marks line up with your experimental peaks.</li>
            </ol>
            
            <h3>Phase 2: Refining the Peak Shape</h3>
            <ol start="4">
                <li><b>Fit the Gaussian Broadening:</b> Once the positions are correct, enable the fit for the primary Gaussian parameters (e.g., <strong>U, V, and W</strong> in Profile #3). These parameters control the majority of the peak width. Run the refinement again.</li>
                <li><b>Introduce Lorentzian and Asymmetry:</b> Now, add the Lorentzian parameters (e.g., <strong>X, Y</strong>) and, if needed, the asymmetry parameter (<strong>S/L</strong>). This should correct most of the remaining mismatch in the peak shapes, particularly the "tails" of the peaks and their low-angle asymmetry.</li>
                <li><b>The Final Polish:</b> For the highest quality fits, you can now introduce the last few parameters. If you notice that some peaks are systematically broader or narrower than your model predicts, consider refining the <strong>anisotropic Stephens parameters</strong> (e.g., S400).</li>
            </ol>

            <h3>Phase 3: Finalizing and Extracting Intensities</h3>
            <ol start="7">
                 <li><b>When to Use Simulated Annealing (SA):</b> If at any point the LM fit seems "stuck" in a bad solution, switch the algorithm to <strong>Simulated Annealing</strong>. Run one cycle to allow the fit to explore a wider parameter space and "jump out" of the false minimum. Then, switch back to LM to converge precisely on the new, better solution.</li>
                <li><b>Switch to Pawley:</b> Once you have a stable and visually pleasing fit with the Le Bail method, you can switch to the <strong>Pawley method</strong> for a final refinement. This will refine the individual integrated intensities as free variables, potentially providing a more accurate and unbiased set of intensities for further analysis.</li>
            </ol>
            <div class="note">
                <strong>Warning on Parameter Correlation:</strong> Be cautious about refining too many parameters at once. Some parameters are "correlated," meaning the algorithm can have trouble distinguishing their effects (e.g., increasing a lattice parameter can have a similar effect to changing the zero-shift). The sequential strategy outlined above helps to minimize these issues and leads to more stable and physically meaningful results.
            </div>
        </section>
        
        <hr>
        

        <section id="results">
            <h2>Interpreting Your Results</h2>
            <p>
                Evaluating the success of your refinement is a two-part process: examining the statistical "R-factors" for a numerical score, and, more importantly, critically inspecting the difference plot for a visual confirmation of the fit quality.
            </p>

            <h3>Numerical Figures of Merit</h3>
            <p>The results panel provides several standard figures of merit to quantify the agreement between the observed ($y_{i,obs}$) and calculated ($y_{i,calc}$) patterns.</p>
            <ul>
                <li>
                    <b>R-pattern ($R_p$):</b> An unweighted measure of the fit. Because it's unweighted, it is mostly sensitive to how well the most intense peaks are modeled.
                    $$R_p = \frac{\sum |y_{i,obs} - y_{i,calc}|}{\sum y_{i,obs}} \times 100\%$$
                </li>
                <li>
                    <b>Weighted R-pattern ($R_{wp}$):</b> This is the most important R-factor. It uses weights ($w_i = 1/y_{i,obs}$) to give more importance to the data points with fewer counts, ensuring that the background and weaker reflections are fitted just as carefully as the strong ones.
                    $$R_{wp} = \left[ \frac{\sum w_i (y_{i,obs} - y_{i,calc})^2}{\sum w_i y_{i,obs}^2} \right]^{1/2} \times 100\%$$
                </li>
                <li>
                    <b>Reduced Chi-squared ($\chi^2$):</b> Often called the Goodness of Fit (GOF or S²), this is the most statistically meaningful indicator. It compares the weighted sum of squared residuals to its expected statistical value. <strong>A perfect fit would have a $\chi^2$ value of exactly 1.0.</strong>
                    <ul>
                        <li>A value much larger than 1.0 indicates that your model is poor and does not adequately describe the data.</li>
                        <li>A value much less than 1.0 might suggest that your estimate of the experimental error is too large.</li>
                    </ul>
                     $$\chi^2 = \frac{\sum w_i (y_{i,obs} - y_{i,calc})^2}{N - P}$$
                </li>
            </ul>

            <h3>The Visual Check: The Most Important Step</h3>
            <p>
                Numerical R-factors can sometimes be misleadingly low even when the fit is physically incorrect. Your eyes are the best judge of quality.
            </p>
            <ul>
                <li>
                    <b>The Difference Plot:</b> The red curve at the bottom of the chart shows the difference between your data and the calculated model. For a perfect fit, this plot should be a flat, featureless line of random noise centered on zero. <strong>Always trust your visual inspection of the difference plot over the R-factors.</strong>
                </li>
                <li>
                    <b>Look for Systematic Errors:</b> If you see "M-shaped" wiggles around the peaks, broad humps, or sharp, unindexed spikes in the difference plot, it means your model is missing something. This could be an incorrect peak shape, unmodeled asymmetry, a poor background fit, or even an impurity phase in your sample that you haven't accounted for.
                </li>
            </ul>

            <h3>Exporting Your Results</h3>
            <p>
                Once you are satisfied with your refinement, you can export a comprehensive report.
            </p>
            <ul>
                <li><b>Save Report:</b> This generates a detailed text file containing all statistics, final parameter values and their uncertainties (ESDs, if using the LM algorithm), and a point-by-point list of the observed, calculated, and difference intensities.</li>
                <li><b>Generate PDF:</b> This creates a polished PDF document with a high-resolution image of your final plot and summary tables of the results, perfect for reports and lab notebooks.</li>
            </ul>
        </section>

        <hr>

        <section id="references">
            <h2>References & Further Reading</h2>
             <div class="reference-item">
                <strong>Pawley Method:</strong><br>
                Pawley, G. S. (1981). "Unit-cell refinement from powder diffraction scans". <em>Journal of Applied Crystallography</em>, 14(6), 357-361.
            </div>
            <div class="reference-item">
                <strong>Le Bail Method:</strong><br>
                Le Bail, A., Duroy, H. & Fourquet, J.L. (1988). "Ab-initio structure determination of LiSbWO6 by X-ray powder diffraction". <em>Materials Research Bulletin</em>, 23(3), 447-452.
            </div>
            <div class="reference-item">
                <strong>GSAS Profile Functions:</strong><br>
                Larson, A. C. & Von Dreele, R. B. (2004). "General Structure Analysis System (GSAS)". <em>Los Alamos National Laboratory Report LAUR 86-748</em>.
            </div>
             <div class="reference-item">
                <strong>TCH Profile Function (Profile #2):</strong><br>
                Thompson, P., Cox, D. E. & Hastings, J. B. (1987). "Rietveld refinement of Debye-Scherrer synchrotron X-ray data from Al2O3". <em>Journal of Applied Crystallography</em>, 20(2), 79-83.
            </div>
            <div class="reference-item">
                <strong>Stephens Anisotropy Model (Profile #3):</strong><br>
                Stephens, P. W. (1999). "Phenomenological model of anisotropic peak broadening in powder diffraction". <em>Journal of Applied Crystallography</em>, 32(2), 281-289.
            </div>
            
                <div class="reference-item">
                <strong>Fullprof Software:</strong><br>
                Rodríguez-Carvajal, J. (1993). "Recent advances in magnetic structure determination by neutron powder diffraction". <em>Physica B: Condensed Matter</em>, 192(1-2), 55-69.
            </div>
            
            <div class="reference-item">
                <strong>GSAS-II Software:</strong><br>
                Toby, B. H. & Von Dreele, R. B. (2013). "GSAS-II: the genesis of a modern open-source all-purpose crystallography software package". <em>Journal of Applied Crystallography</em>, 46(2), 544-549.
            </div>
        </section>

        <hr>
        
        <section id="about">
            <h2>About This Tool</h2>
            <p>
                The <strong>powder5</strong> toolkit was developed by Nita Dragoe from Université Paris-Saclay. It is a modern, browser-based implementation of pattern decomposition methods for powder X-ray diffraction, inspired by concepts present in earlier programs like PowderV2 (Dragoe, N. (2001). <em>J. Appl. Cryst.</em>, 34, 535) and featuring robust profile functions similar to those in GSAS. The implementation of the Pawley method and other modern features are new to this version.
            </p>
            <p>
                Last Updated: 07 October 2025.<br>This document was generate by an AI assistant.
            </p>
            <div class="note">
                <strong>Note:</strong> This application is intended for educational and rapid analysis purposes. While it implements robust and standard algorithms, it is not a substitute for dedicated, peer-reviewed refinement software packages like GSAS-II, FullProf, or TOPAS for publication-quality analysis.
            </div>
        </section>
    </main>
</div>

<script>
    // Simple script for active nav link highlighting on scroll
    document.addEventListener('DOMContentLoaded', () => {
        const contentArea = document.getElementById('content-area');
        const navLinks = document.querySelectorAll('#nav-links a');
        const sections = document.querySelectorAll('#content-area section');

        const activateLink = (id) => {
            navLinks.forEach(link => {
                link.classList.remove('active');
                if (link.getAttribute('href') === `#${id}`) {
                    link.classList.add('active');
                }
            });
        };

        contentArea.addEventListener('scroll', () => {
            let current = '';
            sections.forEach(section => {
                const sectionTop = section.offsetTop;
                if (contentArea.scrollTop >= sectionTop - 100) {
                    current = section.getAttribute('id');
                }
            });
            if (current) {
                activateLink(current);
            }
        });
    });
</script>

</body>
</html>