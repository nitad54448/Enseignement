<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Le Bail Fit - Help</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    
    <script>
        MathJax = {
          tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']]
          },
          svg: {
            fontCache: 'global'
          }
        };
    </script>
    <script type="text/javascript" id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
    </script>

    <style>
        :root {
            --system-blue: #007AFF;
            --system-gray-1: #8E8E93;
            --system-gray-2: #AEAEB2;
            --system-gray-3: #C7C7CC;
            --system-gray-4: #D1D1D6;
            --system-gray-5: #E5E5EA;
            --system-gray-6: #F2F2F7;
            --system-background: #FFFFFF;
            --system-grouped-background: #F2F2F7;
            --system-label: #000000;
            --system-secondary-label: rgba(60, 60, 67, 0.6);
            --system-separator: rgba(60, 60, 67, 0.29);
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Inter', sans-serif;
            margin: 0;
            background-color: var(--system-grouped-background);
            display: flex;
            flex-direction: column;
            height: 100vh;
            color: var(--system-label);
            line-height: 1.7;
            font-size: 16px;
        }

        #app-container {
            display: flex;
            width: 100%;
            height: 100%;
            overflow: hidden;
        }

        #nav-panel {
            width: 280px;
            min-width: 240px;
            flex-shrink: 0;
            padding: 24px;
            background-color: var(--system-background);
            border-right: 1px solid var(--system-separator);
            overflow-y: auto;
        }

        #nav-panel h2 {
            font-size: 18px;
            margin-top: 0;
            margin-bottom: 24px;
            color: var(--system-label);
        }

        #nav-panel ul {
            list-style: none;
            padding: 0;
            margin: 0;
        }

        #nav-panel li a {
            display: block;
            padding: 8px 12px;
            text-decoration: none;
            color: var(--system-secondary-label);
            border-radius: 8px;
            font-weight: 500;
            transition: all 0.2s ease;
            font-size: 15px;
        }
        
        #nav-panel li a.sub-link {
            padding-left: 28px;
            font-size: 14px;
            font-weight: 400;
        }

        #nav-panel li a:hover {
            background-color: var(--system-gray-6);
            color: var(--system-label);
        }

        #nav-panel li a.active {
            background-color: var(--system-blue);
            color: white;
            font-weight: 600;
        }


        #content-area {
            flex-grow: 1;
            padding: 32px 48px;
            overflow-y: auto;
            background-color: var(--system-background);
        }
        
        #content-area h2 {
            font-size: 28px;
            font-weight: 700;
            margin-top: 0;
            padding-bottom: 16px;
            border-bottom: 1px solid var(--system-separator);
            margin-bottom: 24px;
        }
        
        #content-area h3 {
            font-size: 22px;
            font-weight: 600;
            margin-top: 40px;
            margin-bottom: 16px;
            padding-bottom: 8px;
            border-bottom: 1px solid var(--system-gray-5);
        }
        
        #content-area h4 {
            font-size: 18px;
            font-weight: 600;
            margin-top: 24px;
            margin-bottom: 12px;
            color: var(--system-secondary-label);
        }

        code {
            background-color: var(--system-gray-6);
            padding: 2px 6px;
            border-radius: 4px;
            font-family: 'SF Mono', 'Menlo', 'monospace';
            font-size: 0.9em;
            border: 1px solid var(--system-gray-4);
        }
        
        .reference-item {
            margin-bottom: 1em;
        }

        .note {
            background-color: #eef6ff;
            border-left: 4px solid var(--system-blue);
            padding: 16px;
            margin: 24px 0;
            border-radius: 0 8px 8px 0;
        }
    </style>
</head>
<body>

    <div id="app-container">
        <nav id="nav-panel">
            <h2>Help Topics</h2>
            <ul id="nav-links">
                <li><a href="#introduction">Introduction</a></li>
                <li><a href="#getting-started">Getting Started</a></li>
                <li><a href="#chart-interactions">Chart Interactions</a></li>
                <li><a href="#le-bail-method">The Le Bail Method</a></li>
                <li><a href="#algorithms">Refinement Algorithms</a></li>
                <li><a href="#algorithms-lm" class="sub-link">Levenberg-Marquardt</a></li>
                <li><a href="#algorithms-sa" class="sub-link">Simulated Annealing</a></li>
                <li><a href="#parameters">Parameter Guide</a></li>
                <li><a href="#parameters-crystal" class="sub-link">Crystal & Space Group</a></li>
                <li><a href="#parameters-instrumental" class="sub-link">Instrumental</a></li>
                <li><a href="#parameters-background" class="sub-link">Background</a></li>
                <li><a href="#parameters-profile4" class="sub-link">Profile Function #4</a></li>
                <li><a href="#parameters-profile3" class="sub-link">Profile Function #3</a></li>
                <li><a href="#strategy">Refinement Strategy</a></li>
                <li><a href="#results">Interpreting Results</a></li>
                <li><a href="#references">References</a></li>
                <li><a href="#about">About</a></li>
            </ul>
        </nav>

        <main id="content-area">
            <section id="introduction">
                <h2>Introduction</h2>
                <p>
                    This document provides a detailed guide to the browser-based Le Bail Fitting tool. The program is designed for crystallographers and material scientists who need to perform whole-pattern powder diffraction decomposition to determine accurate lattice parameters, integrated intensities, and profile shape parameters.
                </p>
                <p>
                    The tool implements the iterative procedure proposed in the 90's by Armel Le Bail, a CNRS researcher, and utilizes GSAS-style profile functions for robust and flexible peak shape modeling. The available models are a <strong>Simple pseudo-Voigt (Profile Function #4)</strong> and a comprehensive <strong>Anisotropy model (Profile Function #3)</strong>, which combines the classic TCH pseudo-Voigt for isotropic broadening with the Stephens model for anisotropic effects. It is intended as an accessible, rapid analysis tool for researchers familiar with the principles of powder diffraction.
                </p>
            </section>
            
            <hr>
            
            <section id="getting-started">
                <h2>Getting Started: File Loading</h2>
                <p>
                    The analysis begins by loading a powder diffraction data file. The application attempts to automatically parse a variety of common instrument formats. If a specific format is not recognized, it will fall back to a generic two-column parser.
                </p>
                <ul>
                    <li><b>Supported Formats:</b> The tool has dedicated parsers for Bruker (<code>.brml</code>, <code>.uxd</code>), PANalytical (<code>.xrdml</code>), Rigaku (<code>.ras</code>), Philips (<code>.udf</code>), GSAS (supporting both intensity-only bank/XRA format and <code>.esd</code> with intensity-uncertainty pairs), and various two-column ASCII formats (<code>.csv</code>, <code>.xy</code>, <code>.txt</code>).</li>
                    <li><b>Generic Fallback:</b> For unrecognized formats, the parser will attempt to read the data as two-column, space/comma/semicolon-delimited text (2-theta, Intensity). Lines starting with <code>#</code> or <code>//</code> are ignored.</li>
                    <li><b>Wavelength Detection:</b> For instrument-specific formats, the tool will attempt to read the K-alpha1 wavelength from the file header and automatically populate the "Radiation 1 (Å)" field. This should always be verified by the user.</li>
                </ul>
            </section>

            <hr>

            <section id="chart-interactions">
                <h2>Chart Interactions</h2>
                <p>The results plot is interactive, allowing for detailed inspection of the fit once data is loaded.</p>
                <ul>
                    <li><b>Pan:</b> Click and drag anywhere on the plot area to pan the view. This allows you to explore the <strong>entire loaded dataset</strong>, even parts outside of the currently selected fit range.</li>
                    <li><b>Differential Zoom:</b> Use your mouse wheel to zoom. The zoom is anchored to your cursor position and its behavior depends on where the cursor is:
                        <ul>
                            <li><b>Over the main plot area:</b> Zooms both the $2\theta$ and Intensity axes simultaneously.</li>
                            <li><b>Over the Intensity axis (left):</b> Zooms only the vertical Intensity axis.</li>
                            <li><b>Over the $2\theta$ axis (bottom):</b> Zooms only the horizontal $2\theta$ axis.</li>
                        </ul>
                    </li>
                    <li><b>Reset View:</b> To reset the zoom and pan, <strong>right-click</strong> anywhere on the chart. This will reset the view to the <strong>range currently selected by the 2θ sliders</strong>, not the full data range.</li>
                    <li><b>Peak Information:</b> Hover your mouse near a calculated Bragg peak position (the green tick marks) to display a tooltip with the Miller indices (hkl).</li>
                    <li><b>Set Background Anchor:</b> Hold down the <strong>Ctrl</strong> key and <strong>click</strong> on the chart. The nearest experimental data point will be added as a background anchor point.</li>
                </ul>
            </section>
            
            <hr>

            <section id="le-bail-method">
                <h2>The Le Bail Method</h2>
                <p>
                    The Le Bail method is a whole-pattern decomposition technique that refines structural and instrumental parameters without requiring a <em>crystal structure model</em> (i.e., atomic coordinates and displacement parameters). This is its primary advantage, as it bypasses the need for a correct structural model, which is often the most challenging aspect of <em>ab initio</em> structure determination from powder data.
                </p>
                <p>The core of the method is an iterative loop:</p>
                <ol>
                    <li><b>Initialize:</b> Start with initial estimates for lattice parameters and profile parameters. All integrated intensities ($I_{hkl}$) are considered equal.</li>
                    <li><b>Calculate Pattern:</b> Generate a calculated pattern based on the current parameters. Peak positions are determined by the lattice parameters, and peak shapes by the profile parameters.</li>
                    <li><b>Extract Intensities (Le Bail Step):</b> This is the key step. The observed, background-subtracted intensity at each data point ($y_i^{obs}$) is distributed among the contributing calculated Bragg peaks based on their profile values at that point. The sum of these contributions for a given reflection gives a new "observed" integrated intensity, $I_{hkl}^{obs'}$.</li>
                    <li><b>Refine Parameters:</b> The newly extracted $I_{hkl}^{obs'}$ values are now treated as <strong>fixed constants</strong>. A standard least-squares refinement is performed, minimizing the difference between the observed pattern and a new calculated pattern (using the fixed $I_{hkl}^{obs'}$) by varying the <strong>lattice, profile, and instrumental parameters</strong>.</li>
                    <li><b>Iterate:</b> The refined parameters from Step 4 are used as the input for Step 2, and the process repeats until the parameters converge.</li>
                </ol>
                <p>The final extracted integrated intensities can then be used as input for structure solution programs that employ direct methods, Patterson techniques, or charge flipping.</p>
            </section>

            <hr>
            
            <section id="algorithms">
                <h2>Refinement Algorithms</h2>
                <p>The tool provides two different algorithms for minimizing the objective function, $\sum w_i (y_{i,obs} - y_{i,calc})^2$. Each has distinct advantages.</p>

                <h3 id="algorithms-lm">Levenberg-Marquardt (LM)</h3>
                <p>
                    LM is a local least-squares minimization algorithm that intelligently interpolates between the Gauss-Newton algorithm and the method of gradient descent. It is the standard method for non-linear least-squares problems like Rietveld and Le Bail refinement. It works by calculating the Jacobian matrix (the matrix of partial derivatives of the calculated pattern with respect to each parameter) to determine the "downhill" direction in $\chi^2$ space.
                </p>
                <p>
                    <b>Strengths:</b> It is highly efficient and converges rapidly when the initial parameters are reasonably close to the true solution.
                </p>
                <p>
                    <b>Weaknesses:</b> As a local minimizer, it can be prone to getting "stuck" in a local minimum if the starting parameters are poor. Imagine a hiker in a foggy mountain range; LM will efficiently find the bottom of the nearest valley, but that valley might not be the lowest one in the entire range.
                </p>
                
                <h3 id="algorithms-sa">Simulated Annealing (SA)</h3>
                <p>
                    SA is a probabilistic, global optimization method inspired by the metallurgical process of annealing. The algorithm explores the parameter space more broadly. Initially, at a high "temperature" ($T$), it has a significant probability of accepting a new set of parameters even if it results in a worse fit ($\Delta E > 0$). This probability is governed by the Metropolis criterion, $P(\text{accept}) \approx e^{-\Delta E / T}$. This ability allows it to "jump out" of local minima.
                </p>
                <p>
                    As the refinement progresses, $T$ is slowly lowered according to a cooling schedule, and the algorithm becomes more selective, eventually settling into what is hopefully the global minimum.
                </p>
                <div class="note" style="padding: 12px; margin-top: 12px; margin-bottom: 8px;">
                    <strong>Tuning the "Jumpiness":</strong> If you find the SA fit is too erratic, you can make it more conservative by lowering its <strong>initial temperature</strong>. This is done by editing a single line in the <code>refineParametersSA</code> function in the page's HTML source. Reducing the multiplier in <code>let T = current_cost * 0.1;</code> to a smaller value like <code>0.02</code> will make the algorithm less likely to accept "bad" moves, leading to a smoother convergence. You do not need to change the final temperature (`T_min`) when you do this, as the cooling schedule is calculated automatically based on your start/end temperatures and the number of steps.
                </div>
                <p>
                    <b>Strengths:</b> More robust at finding a globally reasonable solution, especially when the initial parameters are uncertain or when LM gets trapped in a false minimum.
                </p>
                <p>
                    <b>Weaknesses:</b> Generally much slower than LM and may not find the precise minimum with as high a precision. It is best used to find a good starting point for a final LM refinement.
                </p>
            </section>
            
            <hr>
            
            <section id="parameters">
                <h2>Parameter Guide</h2>
                <p>This section details the refinable parameters available in the tool.</p>

                <h3 id="parameters-crystal">Crystal System & Space Group</h3>
                <p>
                    The "System" dropdown menu allows you to select the Bravais lattice type. This choice determines which lattice parameters ($a$, $b$, $c$, $\alpha$, $\beta$, $\gamma$) are available for input and refinement, automatically applying the necessary constraints (e.g., for a cubic system, $a=b=c$ and $\alpha=\beta=\gamma=90^\circ$).
                </p>
                <p>
                    The **Space Group** dropdown is filtered based on your choice of system. Selecting a space group is crucial as it determines the reflection conditions used to generate the list of allowed Miller indices ($hkl$).
                </p>

                <h3 id="parameters-instrumental">Instrumental Parameters</h3>
                <p>
                    These parameters define the instrument geometry and radiation source. They are found under the "Sample" tab in the main application.
                </p>
                <ul>
                    <li><code>Radiation 1 (Å)</code>: The primary X-ray wavelength (e.g., K-alpha1). This is typically fixed.</li>
                    <li><code>Radiation 2 (Å)</code>: The secondary X-ray wavelength (e.g., K-alpha2). Set to zero or equal to Radiation 1 if not needed.</li>
                    <li><code>Ratio (I₂/I₁)</code>: The intensity ratio of the secondary to the primary wavelength. A value of ~0.5 is typical for Cu K-alpha radiation. Set to 0 to disable the doublet calculation.</li>
                    <li><code>Zero</code>: The $2\theta$ zero-point error of the instrument. This is a constant offset applied to all calculated peak positions.</li>
                    <li><code>2θ Min / Max</code>: These sliders, found in the "Refinement" panel, define the start and end points of the data range used in the least-squares calculation. Data outside this range is ignored by the algorithm.
                        <div class="note" style="padding: 12px; margin-top: 12px; margin-bottom: 8px;">
                            <strong>Important:</strong> The refined coefficients of the <strong>Chebyshev background polynomial</strong> are highly dependent on this range, as the polynomial is normalized to fit between these limits. Changing the range will necessitate a re-refinement of the background.
                        </div>
                    </li>
                </ul>

                <h3 id="parameters-background">Background Parameters</h3>
                <p>The background is modeled on the "Background" tab using a combination of refinable functions.</p>
                 <ul>
                    <li><b>Chebyshev Polynomial:</b> A flexible 6-term polynomial ($B_0$ to $B_5$) used to model the overall background shape. $B_0$ controls the average height, while higher-order terms model the curvature.</li>
                    <li><b>Amorphous Hump:</b> A Lorentzian-shaped peak used to model broad features from amorphous sample holders or components. It is defined by its <code>Height</code>, <code>Position</code>, and <code>FWHM</code>.</li>
                    <li><b>Anchor Points:</b> You can manually force the background to pass through specific points. By <strong>Ctrl+Clicking</strong> on the chart, you add an anchor point which is given a high weight during refinement. The weight is calculated as $w_i = 1 / \max(y_i, \text{floor})$, where the <strong>floor</strong> is set to 0.1% of the maximum intensity in the fitting range. The anchor point's weight is then boosted by a large multiplier. This ensures numerical stability while strongly guiding the background curve.</li>
                </ul>


                <h3 id="parameters-profile4">Profile Function #4 (Simple pseudo-Voigt)</h3>
                <p>
                    This is a simpler pseudo-Voigt implementation where the Gaussian and Lorentzian components are mixed linearly via a refined mixing parameter, $\eta$.
                    $$ H_G^2 = GU \tan^2\theta + GV \tan\theta + GW + GP / \cos^2\theta $$
                    $$ H_L = LX / \cos\theta $$
                </p>
                <ul>
                    <li><code>GU, GV, GW, GP</code>: Describe the Gaussian broadening from strain and instrumental effects.</li>
                    <li><code>LX</code>: Describes the Lorentzian (crystallite size) broadening.</li>
                    <li><code>eta</code>: The Lorentzian mixing parameter in the pseudo-Voigt function (0=pure Gaussian, 1=pure Lorentzian).</li>
                    <li><code>shft</code>: A peak position shift parameter due to sample displacement.</li>
                    <li><code>trns</code>: A peak position shift parameter due to sample transparency.</li>
                </ul>
                
                <h3 id="parameters-profile3">Profile Function #3 (Anisotropy / TCH)</h3>
                <p>
                    This powerful and flexible function combines two models: the isotropic <strong>Thompson-Cox-Hastings (TCH) pseudo-Voigt</strong> for general peak shape and the <strong>Stephens model</strong> for anisotropic (direction-dependent) strain broadening.
                </p>
                <div class="note">
                    <b>Tip:</b> To use this as a standard isotropic TCH profile (equivalent to the classic GSAS Profile Function #2), simply keep all the Stephens <code>S_hkl</code> parameters (<code>S400</code>, <code>S040</code>, etc.) fixed at a value of zero.
                </div>
                
                <h4>Isotropic Broadening (TCH Model)</h4>
                <p>The Full-Width at Half-Maximum (FWHM) of the Gaussian ($H_G$) and Lorentzian ($H_L$) components have an angular dependence given by:
                    $$ H_G^2 = U \tan^2\theta + V \tan\theta + W $$
                    $$ H_L = X \tan\theta + Y / \cos\theta $$
                </p>
                <ul>
                    <li><code>W</code>: The primary instrumental resolution term, related to the Caglioti formula. It must be positive.</li>
                    <li><code>U, V</code>: The Gaussian strain ($U$) and instrumental ($V$) broadening terms. $U$ must be positive; $V$ is often negative.</li>
                    <li><code>Y, X</code>: The Lorentzian crystallite size ($Y$) and strain ($X$) broadening terms, based on the Scherrer and Stokes-Wilson formulae, respectively.</li>
                </ul>
                
                <h4>Peak Asymmetry</h4>
                 <ul>
                    <li><code>S/L, H/L</code>: Asymmetry parameters that correct for peak shape distortions. <code>S/L</code> primarily models sample displacement/transparency, while <code>H/L</code> models axial divergence.</li>
                </ul>

                <h4>Anisotropic Broadening (Stephens Model)</h4>
                <p>
                    This model adds terms to the Lorentzian FWHM ($H_L$) to account for anisotropic microstrain, where peak widths vary depending on the crystallographic direction $(hkl)$.
                </p>
                <p>
                    The refinable parameters are the coefficients <code>S400, S040, S004, S220, S202, S022</code> in a symmetry-adapted spherical harmonic expansion. The number of independent parameters is determined by the crystal's Laue group symmetry. This tool automatically disables and links parameters based on the selected crystal system to enforce these constraints. For example, in a <strong>cubic</strong> system, only `S400` and `S220` are independent.
                </p>
            </section>

            <hr>
            
            <section id="strategy">
                <h2>Recommended Refinement Strategy</h2>
                <p>
                    A sequential and strategic approach to refinement is more stable and likely to yield a physically meaningful result than enabling all parameters at once.
                </p>
                <ol>
                    <li><b>Initial Setup:</b> Load the data, select the correct crystal system and space group.
                        <ul style="margin-top: 0.5em;">
                            <li>Set the desired <strong>$2\theta$ range for refinement</strong> using the sliders in the "Refinement" panel. This is a critical first step. It is often wise to exclude regions at very low or high angles where the pattern quality is poor, or regions containing known impurity peaks.</li>
                        </ul>
                    </li>
                    <li><b>Background:</b> Go to the "Background" tab. Model the background by refining the Chebyshev coefficients (start with just B0 and B1). Alternatively, for complex backgrounds, <strong>Ctrl+Click</strong> on the chart in background regions to define anchor points.</li>
                    <li><b>Basics First:</b> Begin by refining only the most essential parameters: <strong>Lattice Parameter(s)</strong> and <strong>Zero Shift</strong>. Use a fixed, simple profile shape (e.g., default U,V,W,X,Y values with their fit checkboxes unticked). Use the <strong>Levenberg-Marquardt</strong> algorithm for this.</li>
                    <li><b>Refine Gaussian Shape:</b> Once the peak positions are correct, enable the fit for the primary Gaussian broadening parameters: <strong>U, V, and W</strong> (or GU, GV, GW). Run the refinement again.</li>
                    <li><b>Introduce Lorentzian & Asymmetry:</b> Add the Lorentzian size/strain parameters <strong>X</strong> and <strong>Y</strong> (or LX) and the primary asymmetry parameter <strong>S/L</strong> to the refinement. This will correct the majority of the remaining peak shape mismatch.</li>
                    <li><b>Final Polish:</b> For the highest quality fits, you can now add the remaining parameters. If your peaks show directional broadening, carefully introduce the <strong>anisotropic Stephens parameters</strong>.</li>
                    <li><b>When to Use SA:</b> If at any stage the fit converges to a solution that is clearly incorrect (e.g., a very poor visual fit despite low R-factors), switch to <strong>Simulated Annealing</strong> for one cycle to escape the false minimum, then switch back to LM to finish the refinement.</li>
                </ol>
                <div class="note">
                    <strong>Warning on Stability:</strong> Avoid refining too many parameters simultaneously, especially those that can be highly correlated (e.g., lattice parameters and the zero-shift, or multiple peak shape parameters like GU and GV). This can lead to an unstable refinement, physically meaningless results, or "singular matrix" errors in the LM algorithm. The recommended sequential strategy helps to avoid these issues.
                </div>
            </section>
            
            <hr>
            

            <section id="results">
    <h2>Interpreting Results</h2>
    <p>
        The quality of a fit is judged both numerically through statistical figures of merit and visually by inspecting the difference plot.
    </p>

    <h3>Numerical Figures of Merit (R-factors)</h3>

    <p>The numerical indicators for the quality of the refinement are displayed in the results panel. They are calculated over all <i>N</i> data points in the fitted range.</p>

    <ul>
        <li>
            <b>R-pattern ($R_p$):</b> This is the simplest measure of the difference between the observed ($y_{i,obs}$) and calculated ($y_{i,calc}$) patterns. It is unweighted, making it sensitive to intense peaks but less sensitive to errors in the background or weak reflections. A lower value is better.
            $$R_p = \frac{\sum |y_{i,obs} - y_{i,calc}|}{\sum y_{i,obs}} \times 100\%$$
        </li>
        <li>
            <b>Weighted R-pattern ($R_{wp}$):</b> This is the most statistically significant and widely reported R-factor. It includes a weighting factor ($w_i$) for each data point, which is typically the inverse of the variance. For diffraction data where the uncertainty is dominated by counting statistics, the weight is the inverse of the observed intensity ($w_i = 1/y_{i,obs}$). This gives more weight to data points with lower counts (and thus lower absolute uncertainty), preventing the fit from being dominated by only the strongest peaks.
            $$R_{wp} = \left[ \frac{\sum w_i (y_{i,obs} - y_{i,calc})^2}{\sum w_i y_{i,obs}^2} \right]^{1/2} \times 100\%$$
        </li>
        <li>
            <b>Expected R-factor ($R_{exp}$):</b> This represents the best possible $R_{wp}$ that can be achieved for a given dataset, based purely on the statistical noise. It is determined by the number of data points (<i>N</i>) and the number of refined parameters (<i>P</i>).
            $$R_{exp} = \left[ \frac{N - P}{\sum w_i y_{i,obs}^2} \right]^{1/2} \times 100\%$$
        </li>
        <li>
            <b>Goodness of Fit (GOF or $S$):</b> In GSAS-style refinement, this is often denoted as the Goodness of Fit ($S$). It is the ratio of the achieved $R_{wp}$ to the best possible $R_{exp}$. A value close to 1.0 indicates that the model fits the data to within the statistical noise of the measurement itself.
            $$\text{GOF} = S = \frac{R_{wp}}{R_{exp}}$$
        </li>
        <li>
            <b>Reduced Chi-squared ($\chi^2_{red}$):</b> This is mathematically related to the GOF and is a more direct statistical measure. It is the sum of the squared weighted residuals divided by the number of degrees of freedom ($N-P$). As with the GOF, a value close to 1.0 indicates a statistically ideal fit. A value much greater than 1.0 means the model is poor, while a value much less than 1.0 may suggest that the experimental errors have been overestimated.
            $$\chi^2_{red} = \frac{\sum w_i (y_{i,obs} - y_{i,calc})^2}{N - P} = S^2 = \left(\frac{R_{wp}}{R_{exp}}\right)^2$$
        </li>
    </ul>

    <h3>Visual Check</h3>
    <ul>
        <li>
            <b>Difference Plot:</b> This is arguably the most important indicator of a good fit. The red difference curve ($y_{i,obs} - y_{i,calc}$) should be a flat line of random, uncorrelated noise centered on zero. Any systematic features, such as "M-shaped" wiggles around the peaks, broad humps, or sharp spikes, indicate a deficiency in your model (e.g., incorrect peak shape, asymmetry, background, or unindexed impurity phase). <strong>Always trust a critical visual inspection of the difference plot over the R-factors.</strong>
        </li>
    </ul>

    <h3>Exporting Results</h3>
    <p>
        After a successful refinement, you can export the results using the buttons at the bottom of the control panel.
    </p>
    <ul>
        <li><b>Save Report:</b> Generates a comprehensive plain text (<code>.txt</code>) file containing all refinement statistics, final parameter values with their estimated standard deviations (ESDs, for LM fits), and a detailed point-by-point list of the observed vs. calculated pattern.</li>
        <li><b>Generate PDF:</b> Creates a formatted PDF document containing a high-quality image of the final fit plot, summary tables of parameters and statistics, and a list of extracted intensities. This is suitable for inclusion in reports or lab notebooks.</li>
    </ul>
</section>


            <hr>

            <section id="references">
                <h2>References</h2>
                <div class="reference-item">
                    <strong>Le Bail Method:</strong><br>
                    Le Bail, A., Duroy, H. & Fourquet, J.L. (1988). "Ab-initio structure determination of LiSbWO6 by X-ray powder diffraction". <em>Materials Research Bulletin</em>, 23(3), 447-452.
                </div>
                <div class="reference-item">
                    <strong>GSAS Profile Functions:</strong><br>
                    Larson, A. C. & Von Dreele, R. B. (2004). "General Structure Analysis System (GSAS)". <em>Los Alamos National Laboratory Report LAUR 86-748</em>.
                </div>
                 <div class="reference-item">
                    <strong>TCH Profile Function (Profile #2):</strong><br>
                    Thompson, P., Cox, D. E. & Hastings, J. B. (1987). "Rietveld refinement of Debye-Scherrer synchrotron X-ray data from Al2O3". <em>Journal of Applied Crystallography</em>, 20(2), 79-83.
                </div>
                <div class="reference-item">
                    <strong>Stephens Anisotropy Model (Profile #3):</strong><br>
                    Stephens, P. W. (1999). "Phenomenological model of anisotropic peak broadening in powder diffraction". <em>Journal of Applied Crystallography</em>, 32(2), 281-289.
                </div>
                
                    <div class="reference-item">
                    <strong>Fullprof Software:</strong><br>
                    Rodríguez-Carvajal, J. (1993). "Recent advances in magnetic structure determination by neutron powder diffraction". <em>Physica B: Condensed Matter</em>, 192(1-2), 55-69.
                </div>
                
                <div class="reference-item">
                    <strong>GSAS-II Software:</strong><br>
                    Toby, B. H. & Von Dreele, R. B. (2013). "GSAS-II: the genesis of a modern open-source all-purpose crystallography software package". <em>Journal of Applied Crystallography</em>, 46(2), 544-549.
                </div>
            </section>

            <hr>
            
            <section id="about">
                <h2>About This Tool</h2>
                <p>
                    This browser-based Le Bail fitting tool was developed by Nita Dragoe from Université Paris-Saclay. An old version was written in Visual Basic and Fortran and reported in Dragoe, N. (2001). "PowderV2: a suite of applications for powder X-ray diffraction calculations". <em>Journal of Applied Crystallography</em>, 34, 535.
                </p>
                <p>
                    Last Updated: 05 October 2025, version 2.5.<br>
                    This documentation was generated by an AI assistant.
                </p>
                <div class="note">
                    <strong>Note:</strong> This application is intended for educational and rapid analysis purposes. While it implements robust and standard algorithms, it is not a substitute for dedicated, peer-reviewed refinement software packages like GSAS-II, FullProf, or TOPAS for publication-quality analysis.
                </div>
            </section>
        </main>
    </div>

    <script>
        // Simple script for active nav link highlighting on scroll
        document.addEventListener('DOMContentLoaded', () => {
            const contentArea = document.getElementById('content-area');
            const navLinks = document.querySelectorAll('#nav-links a');
            const sections = document.querySelectorAll('#content-area section');

            const activateLink = (id) => {
                navLinks.forEach(link => {
                    link.classList.remove('active');
                    if (link.getAttribute('href') === `#${id}`) {
                        link.classList.add('active');
                    }
                });
            };

            contentArea.addEventListener('scroll', () => {
                let current = '';
                sections.forEach(section => {
                    const sectionTop = section.offsetTop;
                    if (contentArea.scrollTop >= sectionTop - 100) {
                        current = section.getAttribute('id');
                    }
                });
                if (current) {
                    activateLink(current);
                }
            });
        });
    </script>
</body>
</html>